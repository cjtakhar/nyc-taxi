# ğŸš– NYC Taxi Data Pipeline

### *A Modern Data Engineering Project (Airflow â€¢ Postgres â€¢ dbt â€¢ Docker)*

This project implements a **full modern data engineering pipeline** using:

* **Apache Airflow** for workflow orchestration
* **Postgres** as a local data warehouse
* **dbt** for transformations and analytics modeling
* **Docker Compose** for a fully reproducible environment
* **Python** for bulk ingestion (Parquet â†’ Postgres)

It ingests **real NYC Yellow Taxi data**, loads it into a warehouse, transforms it with dbt, and prepares it for analytics and dashboards â€” all locally and fully containerized.

---

## ğŸ—ï¸ Architecture

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Parquet     â”‚
          â”‚ NYC Taxi Data â”‚ 
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚      Airflow DAG     â”‚
      â”‚  bulk_load task      â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Postgres Warehouse   â”‚
      â”‚ raw_nyc_taxi_trips   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚         dbt          â”‚
      â”‚  staging / marts     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Components

### **1. Apache Airflow**

* Runs inside Docker
* Hosts the DAG: `nyc_taxi_bulk_load_pipeline`
* Orchestrates ingestion + transformation

### **2. Postgres Warehouse**

Two Postgres instances:

* `airflow-postgres` â†’ Airflow metadata
* `warehouse-postgres` â†’ `nyc_taxi` warehouse DB

### **3. dbt**

* Cleans, models, and tests data
* Staging model: `stg_taxi_trips.sql`
* Schema tests in `schema.yml`

---

## ğŸš€ Features

### âœ¨ **High-performance raw ingestion (Parquet â†’ Postgres)**

`airflow/scripts/bulk_load_nyc_taxi.py`:

* Reads Parquet
* Normalizes columns
* Creates raw table
* Bulk-loads using Postgres `COPY`

### âœ¨ **Orchestrated with Airflow**

`airflow/dags/nyc_taxi_pipeline_dag.py`:

* Automates ingestion
* Runs as a single DAG task

### âœ¨ **dbt transformations**

Under `/dbt`:

* Staging layer
* Data tests
* Marts (optional)

---

## ğŸ› ï¸ Getting Started

### **Prerequisites**

* Docker Desktop
* (Optional) Python 3.10+

---

## ğŸ”§ Setup

Clone and enter the project:

```bash
git clone https://github.com/cjtakhar/nyc-taxi
cd nyc-taxi
```

Ensure this structure exists:

```
nyc-taxi/
  airflow/
    dags/
    scripts/
  data/
    yellow_tripdata_2023-01.parquet
  dbt/
  docker-compose.yml
```

---

## â–¶ï¸ Run the Pipeline

### **1. Initialize Airflow**

```bash
docker compose up airflow-init
```

### **2. Start Airflow Webserver + Scheduler**

```bash
docker compose up -d airflow-webserver airflow-scheduler
```

### Open the UI

ğŸ‘‰ [http://localhost:8080](http://localhost:8080)
Login (if manually created):

```
admin / admin
```

---

## ğŸ§ª Run the DAG

In the Airflow UI:

1. Enable `nyc_taxi_bulk_load_pipeline`
2. Click **Trigger DAG**
3. Watch task logs & Graph view

---

## ğŸ“Š Validate Load in Postgres

Connect:

```bash
psql -h localhost -p 5433 -U nyc_taxi -d nyc_taxi
# password: nyc_taxi
```

Query:

```sql
SELECT COUNT(*) FROM raw_nyc_taxi_trips;
```

If rows appear â†’ ğŸ‰ ingestion succeeded.

---

## ğŸ§± Run dbt Models

```bash
docker exec -it airflow-webserver bash
cd /opt/airflow/dags/dbt/nyc_taxi
dbt run
dbt test
```

---

## ğŸ¯ Roadmap

* Load multiple months
* Add fact tables / marts
* Build dashboards (Looker Studio / Metabase)
* Add alerts (Slack / Email)
* Add S3 ingestion
* Deploy on MWAA / Astronomer

---

## ğŸ“Œ Summary

This project demonstrates:

âœ” Data ingestion engineering
âœ” Workflow orchestration with Airflow
âœ” RAW â†’ staging â†’ marts modeling in dbt
âœ” Postgres as a local warehouse
âœ” Modern Data Stack principles
âœ” Fully containerized reproducible environment

---

